{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bef0c74",
   "metadata": {},
   "source": [
    "https://tcoil.info/stock-price-trend-prediction-using-neural-network-with-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab941434",
   "metadata": {},
   "source": [
    "Get the Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a23cafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib as ta\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c30b844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#suppress 'SettingWithCopy' warning\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c886546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas_datareader\n",
    "#!pip3 install seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17443223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# ___library_import_statements___\n",
    "import pandas as pd\n",
    "\n",
    "# for pandas_datareader, otherwise it might have issues, sometimes there is some version mismatch\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "\n",
    "# make pandas to print dataframes nicely\n",
    "pd.set_option('expand_frame_repr', False)  \n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "#newest yahoo API \n",
    "import yfinance as yahoo_finance\n",
    "\n",
    "#optional \n",
    "#yahoo_finance.pdr_override()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b27b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib as ta\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# was giving me some warnings\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc0f013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___variables___\n",
    "#ticker = 'AAPL'\n",
    "#ticker = 'TSLA'\n",
    "#ticker = 'FB'\n",
    "#ticker = 'MSFT'\n",
    "#ticker = 'NFLX'\n",
    "#ticker = 'GOOGL'\n",
    "ticker = 'BIDU'\n",
    "#ticker = 'AMZN'\n",
    "#ticker = 'IBM'\n",
    "\n",
    "start_time = datetime.datetime(1980, 1, 1)\n",
    "#end_time = datetime.datetime(2019, 1, 20)\n",
    "end_time = datetime.datetime.now().date().isoformat()         # today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e43ad59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "                  Open        High         Low       Close   Adj Close    Volume\n",
      "Date                                                                            \n",
      "2021-03-01  303.339996  303.899994  291.079987  295.579987  295.579987   9804900\n",
      "2021-03-02  296.880005  308.500000  294.000000  301.929993  301.929993  10498100\n",
      "2021-03-03  304.200012  311.179993  271.890015  277.799988  277.799988  12461600\n",
      "2021-03-04  272.220001  279.160004  253.539993  260.589996  260.589996  20227700\n",
      "2021-03-05  266.250000  271.000000  233.899994  261.720001  261.720001  15975600\n",
      "...                ...         ...         ...         ...         ...       ...\n",
      "2021-06-23  190.139999  192.309998  188.850006  189.169998  189.169998   3072700\n",
      "2021-06-24  190.839996  195.710007  190.449997  194.770004  194.770004   4407800\n",
      "2021-06-25  199.000000  203.029999  197.710007  202.639999  202.639999   7371700\n",
      "2021-06-28  205.089996  209.169998  202.949997  205.179993  205.179993   6407400\n",
      "2021-06-29  203.949997  208.919998  201.330002  207.669998  207.669998   4633800\n",
      "\n",
      "[85 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data = yahoo_finance.download(ticker, start=\"2021-03-01\", end=\"2021-06-30\")\n",
    "print (data)\n",
    "data.reset_index()\n",
    "df = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e58ce",
   "metadata": {},
   "source": [
    "Compute various stock technical indicators\n",
    "\n",
    "For each stock we compute several technical indicators, we use mainly exponencial moving averages, Bollinger Bands, RSI and so on. We will then feed these into neural network as features (or values derived from these indicators).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00480bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_technical_indicators(df):\n",
    "    df['EMA5'] = ta.EMA(df['Adj Close'].values, timeperiod=5)\n",
    "    df['EMA10'] = ta.EMA(df['Adj Close'].values, timeperiod=10)\n",
    "    df['EMA15'] = ta.EMA(df['Adj Close'].values, timeperiod=15)\n",
    "    df['EMA20'] = ta.EMA(df['Adj Close'].values, timeperiod=10)\n",
    "    df['EMA30'] = ta.EMA(df['Adj Close'].values, timeperiod=30)\n",
    "    df['EMA40'] = ta.EMA(df['Adj Close'].values, timeperiod=40)\n",
    "    df['EMA50'] = ta.EMA(df['Adj Close'].values, timeperiod=50)\n",
    "\n",
    "    df['EMA60'] = ta.EMA(df['Adj Close'].values, timeperiod=60)\n",
    "    df['EMA70'] = ta.EMA(df['Adj Close'].values, timeperiod=70)\n",
    "    df['EMA80'] = ta.EMA(df['Adj Close'].values, timeperiod=80)\n",
    "    df['EMA90'] = ta.EMA(df['Adj Close'].values, timeperiod=90)\n",
    "    \n",
    "    df['EMA100'] = ta.EMA(df['Adj Close'].values, timeperiod=100)\n",
    "    df['EMA150'] = ta.EMA(df['Adj Close'].values, timeperiod=150)\n",
    "    df['EMA200'] = ta.EMA(df['Adj Close'].values, timeperiod=200)\n",
    "\n",
    "    df['upperBB'], df['middleBB'], df['lowerBB'] = ta.BBANDS(df['Adj Close'].values, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "\n",
    "    df['SAR'] = ta.SAR(df['High'].values, df['Low'].values, acceleration=0.02, maximum=0.2)\n",
    "\n",
    "    # we will normalize RSI\n",
    "    df['RSI'] = ta.RSI(df['Adj Close'].values, timeperiod=14)\n",
    "\n",
    "    df['normRSI'] = ta.RSI(df['Adj Close'].values, timeperiod=14) / 100.0\n",
    "    \n",
    "    df.tail()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2f5b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = compute_technical_indicators(df)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0145806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(df):\n",
    "    # computes features for forest decisions\n",
    "    df['aboveEMA5'] = np.where(df['Adj Close'] > df['EMA5'], 1, 0)\n",
    "    df['aboveEMA10'] = np.where(df['Adj Close'] > df['EMA10'], 1, 0)\n",
    "    df['aboveEMA15'] = np.where(df['Adj Close'] > df['EMA15'], 1, 0)\n",
    "    df['aboveEMA20'] = np.where(df['Adj Close'] > df['EMA20'], 1, 0)\n",
    "    df['aboveEMA30'] = np.where(df['Adj Close'] > df['EMA30'], 1, 0)\n",
    "    df['aboveEMA40'] = np.where(df['Adj Close'] > df['EMA40'], 1, 0)\n",
    "    \n",
    "    df['aboveEMA50'] = np.where(df['Adj Close'] > df['EMA50'], 1, 0)\n",
    "    df['aboveEMA60'] = np.where(df['Adj Close'] > df['EMA60'], 1, 0)\n",
    "    df['aboveEMA70'] = np.where(df['Adj Close'] > df['EMA70'], 1, 0)\n",
    "    df['aboveEMA80'] = np.where(df['Adj Close'] > df['EMA80'], 1, 0)\n",
    "    df['aboveEMA90'] = np.where(df['Adj Close'] > df['EMA90'], 1, 0)\n",
    "    \n",
    "    df['aboveEMA100'] = np.where(df['Adj Close'] > df['EMA100'], 1, 0)\n",
    "    df['aboveEMA150'] = np.where(df['Adj Close'] > df['EMA150'], 1, 0)\n",
    "    df['aboveEMA200'] = np.where(df['Adj Close'] > df['EMA200'], 1, 0)\n",
    "\n",
    "    df['aboveUpperBB'] = np.where(df['Adj Close'] > df['upperBB'], 1, 0)\n",
    "    df['belowLowerBB'] = np.where(df['Adj Close'] < df['lowerBB'], 1, 0)\n",
    "    \n",
    "    df['aboveSAR'] = np.where(df['Adj Close'] > df['SAR'], 1, 0)\n",
    "   \n",
    "    df['oversoldRSI'] = np.where(df['RSI'] < 30, 1, 0)\n",
    "    df['overboughtRSI'] = np.where(df['RSI'] > 70, 1, 0)\n",
    "\n",
    "\n",
    "    # very important - cleanup NaN values, otherwise prediction does not work\n",
    "    df=df.fillna(0).copy()\n",
    "    \n",
    "    df.tail()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d13b5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = compute_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73832500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_data(df):\n",
    "    # plot price\n",
    "    plt.figure(figsize=(15,2.5))\n",
    "    plt.title('Stock data ' + str(ticker))\n",
    "    plt.plot(df['Date'], df['Adj Close'])\n",
    "    #plt.title('Price chart (Adj Close) ' + str(ticker))\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7095b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_target_condition(df):\n",
    " \n",
    "    # price higher later - bad predictive results\n",
    "    #df['target_cls'] = np.where(df['Adj Close'].shift(-34) > df['Adj Close'], 1, 0)    \n",
    "    \n",
    "    # price above trend multiple days later\n",
    "    df['target_cls'] = np.where(df['Adj Close'].shift(-34) > df.EMA150.shift(-34), 1, 0)\n",
    "\n",
    "    # important, remove NaN values\n",
    "    df=df.fillna(0).copy()\n",
    "    \n",
    "    df.tail()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f23e0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = define_target_condition(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13dcbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.reset_index()\n",
    "#plot_train_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e81b589",
   "metadata": {},
   "source": [
    "Create one large training dataframe - without getting the technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00cdbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['F', 'IBM', 'GE', 'AAPL', 'ADM',\n",
    "           'XOM', 'GM','MMM','KO','PEP','SO','GS']           \n",
    "#           'HAS','PEAK','HPE','HLT','HD','HON','HRL','HST','HPQ','HUM','ILMN', \n",
    "#           'INTC','ICE','INTU','ISRG','IVZ','IRM','JNJ','JPM','JNPR','K','KMB', \n",
    "#           'KIM', 'KMI','KSS','KHC', 'KR',  'LB', 'LEG', 'LIN', 'LMT','LOW',\n",
    "#           'MAR', 'MA','MCD','MDT', 'MRK', 'MET', 'MGM', 'MU','MSFT', 'MAA', \n",
    "#           'MNST', 'MCO','MS', 'MSI',\n",
    "#           'MMM', 'ABT','ACN','ATVI','ADBE','AMD','A','AKAM','ARE','GOOG','AMZN','AAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a52ecd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "                  Open        High         Low       Close   Adj Close     Volume\n",
      "Date                                                                             \n",
      "2021-03-01  385.589996  390.920013  380.570007  389.579987  387.041931  105348800\n",
      "2021-03-02  389.820007  390.070007  386.000000  386.540009  384.021790   79595300\n",
      "2021-03-03  385.790009  386.829987  381.309998  381.420013  378.935150  119940200\n",
      "2021-03-04  381.220001  384.000000  371.880005  376.700012  374.245880  183433000\n",
      "2021-03-05  380.459991  384.760010  372.640015  383.630005  381.130737  152039600\n",
      "...                ...         ...         ...         ...         ...        ...\n",
      "2021-06-23  423.190002  424.049988  422.510010  422.600006  422.600006   49445400\n",
      "2021-06-24  424.890015  425.549988  424.619995  425.100006  425.100006   45110300\n",
      "2021-06-25  425.899994  427.089996  425.549988  426.609985  426.609985   58129500\n",
      "2021-06-28  427.170013  427.649994  425.890015  427.470001  427.470001   53159600\n",
      "2021-06-29  427.880005  428.559998  427.130005  427.700012  427.700012   35970500\n",
      "\n",
      "[85 rows x 6 columns]\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# parent dataframe to append to\n",
    "ticker = 'SPY'\n",
    "#df = get_data(ticker)\n",
    "data = yahoo_finance.download(ticker, start=\"2021-03-01\", end=\"2021-06-30\")\n",
    "print (data)\n",
    "data.reset_index()\n",
    "df = data\n",
    "df = compute_technical_indicators(df)\n",
    "df = compute_features(df)\n",
    "df = define_target_condition(df)\n",
    "\n",
    "for ticker in tickers:\n",
    "    #t_df = get_data(ticker)\n",
    "    t_df = yahoo_finance.download(ticker,start=\"2021-03-01\", end=\"2021-06-30\" )\n",
    "    t_df = compute_technical_indicators(t_df)\n",
    "    t_df = compute_features(t_df)\n",
    "    t_df = define_target_condition(t_df)\n",
    "    \n",
    "    df = df.append(t_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb163d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbe1574a",
   "metadata": {},
   "source": [
    "Training - Test Split and Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c34a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_list = ['aboveSAR','aboveUpperBB','belowLowerBB','normRSI','oversoldRSI','overboughtRSI',\n",
    "                   'aboveEMA5','aboveEMA10','aboveEMA15','aboveEMA20','aboveEMA30','aboveEMA40',\n",
    "                   'aboveEMA50','aboveEMA60','aboveEMA70','aboveEMA80','aboveEMA90','aboveEMA100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "edc0fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_and_training(df, predictors_list, test_size=0.3):\n",
    "    # __predictors__\n",
    "\n",
    "\n",
    "    # __features__\n",
    "    X = df[predictors_list].fillna(0).values\n",
    "    #X.tail()\n",
    "\n",
    "    # __targets__\n",
    "    y_cls = df.target_cls.fillna(0).values\n",
    "    #y_cls.tail(10)\n",
    "\n",
    "    # __train test split__\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    y=y_cls\n",
    "    X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    print (X_cls_train.shape, y_cls_train.shape)\n",
    "    print (X_cls_test.shape, y_cls_test.shape)\n",
    "\n",
    "    return X_cls_train, X_cls_test, y_cls_train, y_cls_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a02414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ START OF MAIN SOURCE FROM KAGGLE ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6b7d11c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\WorkingPython\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-5a1c3b38fb4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\WorkingPython\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     raise ImportError(\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n",
      "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3cebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,100)\n",
    "        self.layer2 = nn.Linear(100, 30)\n",
    "        self.layer3 = nn.Linear(30, 2)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.softmax(self.layer3(x)) # To check with the loss function\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182002c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
